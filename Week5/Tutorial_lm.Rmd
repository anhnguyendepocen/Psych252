Psych 252: Running General Linear Models with `lm()`
========================================================

Load in data
-------------
```{r}
d0 = read.csv("http://www.stanford.edu/class/psych252/data/mentillness.csv")
str(d0)
summary(d0)
```

### Factoring categorical variables
After we've loaded in the data, we should always check which variables we might need to factor. Here, we'll start by factoring mental illness, since the defendants fall into one of two discrete categories; normal (not mentally ill), or mentally ill.

```{r}
d0$mentill = factor(d0$mentill, label=c('Normal','Mentally Ill'))
str(d0)
```

Visualize data
-------------
It's always a good idea to see what trends might exist in your data; this will be helpful later on, when interpreting possible interactions, etc.

Simplest plot:

```{r simple boxplots}
with(d0, plot(mentill, futhrt))
```

```{r ggplot}
library(ggplot2)

ggplot(d0, aes(x=mentill, y=futhrt)) + 
  geom_boxplot() + 
  stat_summary(fun.y=mean, geom="point", shape=5, size=4)

ggplot(d0, aes(x=futhrt, y=guilt, color=mentill)) +
  geom_point(shape=1, position=position_jitter(width=.25,height=.25)) +
  geom_smooth(method=lm, fullrange=TRUE)
```

Generate Hypotheses
-------------------
How does perceived **mental illness** of the defendant influence how much the participant thinks the defendant will be a **future threat**?

Possible explanations?
1. If a person is mentally ill, they might cause a lot of harm to society, but not necessarily know why; they might be worse at controlling their actions.
2. A person who is not mentall ill might commit specific crimes against people they know (e.g., if someone found out their significant other was cheating on them, they might harm the person who was cheating), and thus not pose as big a threat to everyone in society.

```{r}
str(d0)
levels(d0$mentill)

# get some summary stats
library(psych)
describeBy(d0$futhrt, group = d0$mentill, mat=TRUE)

# another way to get some quick stats:
library(plyr)
ddply(d0,~mentill,summarise,
      mean=mean(futhrt),
      sd=sd(futhrt),
      n=length(futhrt))
```

Here, we can see that **mental illness** is *categorical*; it has the value of "not mentally ill/normal" or "mentally ill". Perceived **future threat** is continuous, since participants rated this variable on a scale.

By looking at the summary statistics, we can see that the mean perceived future threat for normal people = 3.633, and the mean perceived threat for mentally ill people = 4.433.

Testing Hypotheses
-------------------
Does perceived **mental illness** of the defendant influence how much the participant thinks the defendant will be a **future threat**?

To test this, we could use an unpaired t-test (since there are only two groups), or a general linear model (i.e., `lm()`). The results should be the same in either case.

First, let's use a t-test:
```{r}
# are the variances in futhrt equal between mental illness groups?
bartlett.test(futhrt~mentill, data = d0)

?t.test
t.test(futhrt~mentill, data = d0, paired = FALSE, var.equal=TRUE) -> t1; print(t1) 

## compare to paired
t.test(futhrt~mentill, data = d0, paired = TRUE, var.equal=TRUE) 

```

Now, let's test this same question using a general linear model:
```{r}
rs1 = lm(futhrt~mentill, data = d0)
summary(rs1)
anova(rs1)

(t1$statistic) ^ 2 # Remember that t ^ 2 is approximately equal to F!
```

Here, we can see that the anova() output is identical to the t-test we ran above. However, we get some more information when looking at the lm() output. Here, the estimate for the intercept (i.e., `3.633`) gives us the `y-intercept` for our model; this is the value of `futhrt` where `mentill` = 0. In other words, this is the mean value of `futhrt` for the *control* group of `mentill`. That is, since mental illness is categorical, `lm()` automatically **dummy-codes** the variable. That means that one condition is treated as a "control" (and coded as 0), and the other condition(s) are compared to that control via the dummy-coding. 

To get a sense for this, let's take a look at the default dummy contrasts:
### Contrasts
```{r}
contrasts(d0$mentill)
```

We can see that the column `Mentally Ill` gives `Normal` a value of 0, and `Mentally Ill` a value of 1. As a result, the `Normal` level of `mentill` is treated as the control, and the `lm()` will compare the level `Mentally Ill` to the `Normal` level.

As we can see from the output of the `lm()`, the **intercept estimate gives us the mean value of future threat for the Normal condition**. 

In addition the `mentillMentally Ill` estimate is giving us the results from the first column of our contrasts for `mentill` (in this case, our *only* column), that is called `Mentally Ill`. The `estimate` for this contrast is basically the difference between the mean futhrt of our `Mentally Ill` group, relative to our `Normal` group. Thus, we can derive the **mean value of future threat for the Mentally Ill condition by adding the estimate (i.e., slope) to the intercept; this gives us 3.633 + 0.800 = 4.433, the mean perceived future threat for the Mentally Ill group.**

```{r}
mean(d0$futhrt[d0$mentill=='Mentally Ill'])
```

More complicated questions (testing the relationship between multiple variables)
-------------------------------------------------

Now let's take a look at a more complicated model.  What would we expect if we looked at whether mental illness and perceptions of being a future threat predict judgments of guilt?  Would we predict main effects?  Interactions?

Mental illness: Categorical IV
Future threat: Continuous IV

Guilt: Continuous DV
(1 = Definitely Not Guilty, 2 = Probably Not Guilty, 3 = Probably Guilty, or 4 = Definitely Guilty)

Let's start out with the simplest model.
```{r}

m1 = lm(guilt~futhrt, d0) # What kind of test is this?
summary(m1)

```

Seems like as judges perceive a target to be a greater future threat, they are more likely to think the defendant is guilty. Let's explore some different ways to plot this.

```{r plotting options}

with(d0, plot(futhrt, guilt))
lines(abline(m1, col='green'))

ggplot(d0, aes(x=futhrt, y=guilt)) + 
  geom_point(shape=1) +  # Use hollow circles
  geom_smooth(method=lm, fullrange=TRUE) # Add linear regression line 
                         #  (by default includes 95% confidence region, to remove
                         #   use se=FALSE)

ggplot(d0, aes(x=futhrt, y=guilt)) + 
  geom_point(shape=1, position=position_jitter(width=.5,height=.25)) +  
  geom_smooth(method=lm, fullrange=TRUE)

```

Let's move on to a more complicated model.

```{r}

m2 = lm(guilt~futhrt + mentill, d0)
summary(m2)

```

What kind of model is this? 
Additive!

What would we conclude from this output? 

```{r qplot}

qplot(x = futhrt, y= guilt, data= d0, geom=c("jitter", "smooth"), 
   method="lm", se=FALSE, color= mentill, 
   main="Predictors of Perceived Guilt", 
   xlab="Future Threat", ylab="Guilt")

```

What does it look like is going on in this plot?

Let's check out a more complicated model

```{r interactive}

m3 = lm(guilt~futhrt * mentill, d0)
summary(m3)

````

What would we conclude from this output?

```{r plots}

with(d0, interaction.plot(futhrt, mentill, guilt, col = 2:3))  # Not the best, plotting mean for each value of the continuous variable "futhrt" 

ggplot(d0, aes(x=futhrt, y=guilt, colour=mentill)) +  # Adding color for mentill
  geom_point(shape=1, position=position_jitter(width=1,height=.5)) +  
  geom_smooth(method=lm, se=FALSE) +
  theme_bw()

```

Let's center this model!

```{r}
m5c = lm(guilt~ I(futhrt - mean(futhrt)) * mentill, d0)
summary(m5c)

ggplot(d0, aes(x=scale(futhrt), y=guilt, colour=mentill)) +  # Adding color for mentill
  geom_point(shape=1, position=position_jitter(width=1,height=.5)) +  
  geom_smooth(method=lm, se=FALSE) +
  theme_bw()
```

Note what changed in the coefficients - why would this have changed?

Now let's explore whether there is a quadratic relationship in our data.

```{r poly add}

m4 = lm(guilt~poly(futhrt,2) + mentill, d0)
summary(m4)

````

How might we plot this?

```{r loess}

ggplot(d0, aes(x=futhrt, y=guilt, colour=mentill)) + 
  geom_point(shape=1, position=position_jitter(width=1,height=.5)) +  
  geom_smooth(method='loess',se=FALSE) # remove "method=lm", loess smooth fit curve!

```

Interactive model

```{r poly}

m5 = lm(guilt~poly(futhrt,2) * mentill, d0)
summary(m5)

````

So how do we decide which model is best?

```{r model comparison}

anova(m1, m2, m3) # why wouldn't we compare m4?

anova(m3, m4) 

m4a <- lm(guilt ~ poly(futhrt,2), d0)
anova(m1, m4a, m4)

anova(m2, m4)

```

```{r}

anova(m4, m5)

```

Which model would we use?