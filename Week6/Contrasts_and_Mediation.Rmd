Section 10.30.2013 - Interactions, Contrasts, and Mediation
========================================================
## Homework Question A 

What question are we trying to answer?

*Do family-friendly programs in organizations (e.g., flexible work hours, on-site childcare, etc.) have an effect on employee satisfaction?*

Let's clear out our working space, load in the data, etc.
```{r workspace}
rm(list=ls())

d<-read.csv("http://www.stanford.edu/class/psych252/data/families.csv")
```

Taking a look at the data.

```{r data}
str(d)
summary(d)
```

Now we know that we have:
`N = 68` companies in our sample

**Measures**

`famprog:` the amount of family-friendly programs from (1) Nothing at all to (9) Amazing family-friendliness

`empsatis:` the average rating of employee satisfaction from (1) Extremely unsatisfied to (7) Extremely satisfied

`perfam:` the percentage of employees with families in the organization from 0% to 100%

**(a) Describe the data**

First let's summarize the data
```{r}
library(psych)
describe(d)
```

Now, to look at the relationships between variables, we'll visualize the data w/plots.
Note the plots in your homework! The plot on the right can only be created if you factor the variables. (We'll do this later, because we probably would want to keep these variables as continuous when working with them.) The coplot you can create using continuous variables!

```{r coplot}
with(d, coplot(empsatis ~ famprog | perfam, rows=1, number=5))
```

Note the package `effects` also gives some cool visualizations of continuous interactions:
```{r}
install.packages('effects')
library(effects)
plot(allEffects(lm(empsatis ~ perfam * famprog, data = d)))
```

Let's also take a moment to check out our main DV, employee satisfaction.
```{r}
require(ggplot2)

# Histogram overlaid with kernel density curve
ggplot(d, aes(x=empsatis)) + 
  geom_histogram(aes(y=..density..),
                 binwidth=.5,
                 colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666")  # Overlay with transparent density plot
```

We can also look at the correlations between all the variables. This will give us a better idea of the **main effects**.
```{r}
install.packages("gpairs")
library(gpairs)
gpairs(d, upper.pars = list(scatter = "lm",
                         conditional = "barcode",
                         mosaic = "mosaic"),
       lower.pars = list(scatter = "stats",
                         conditional = "boxplot",
                         mosaic = "mosaic"),
       stat.pars = list(fontsize = 14, signif = 0.05, 
                        verbose = FALSE, use.color = TRUE, 
                        missing = 'missing', just = 'centre'))
```

**(c) Main effects: Does the number of programs affect employee satisfaction? Is the percentage of families who use the programs correlated with employee satisfaction?**

First, we could run a simple regression where `famprog`, the number of family-friendly programs, predicts `empsatis`, employee satisfaction:
```{r simple reg}
# Plot
qplot(x=scale(famprog, scale=FALSE), y=empsatis, data =d) + 
  stat_smooth(method=lm, formula=y~x)

# Stats
e_by_famprog = lm(empsatis ~ scale(famprog, scale=FALSE), data = d)
summary(e_by_famprog)
```

Seems like the answer is yes, but we have a weak (i.e., **marginal**) effect. Can we do something to describe the data better? Taking a look at our plot, what do we think might be going on?

We could use our other predictor `perfam`, and look for an interaction with family programs on employee satisfaction:
```{r interaction continuous}
# Plot just perfam
qplot(x=scale(perfam, scale=FALSE), y=empsatis, data =d) + 
  stat_smooth(method=lm, formula=y~x)

e_by_famprogXperfam = lm(empsatis ~ scale(famprog, scale=FALSE) * 
                           scale(perfam, scale=FALSE), data = d)
summary(e_by_famprogXperfam)
```

Now that we see the expected interaction how do we interpret the simple effects? We will see how to get a decent interpretation later. For now we know that it can't possibly mean that there is a negative relationship between famprog and satisfaction because we saw the data and the model above. 

Compare the p-value of `famprog` with that obtained without an interaction term!

**(c) Do family-friendly programs improve employee satisfaction overall?**

Answer: Yes, there is a marginal positive main effect of the number of family programs on employee satisfaction, and we would report the b, t, df, and p, and then give a short interpretation of the results.
Use df from residual SE at bottom of lm output
`b = .07, t(64) = 1.84, p = .07`

**(d) Does the percentage of employees with families impact the effect of family programs on employee satisfaction?**

Answer: There is a significant interaction between the number of family programs available and the percentage of families who use these programs,
`b = .007, t(64) = 2.06, p = .04`

**(e) Interpret the answer by examining the effect of family programs on employee satisfaction for companies who have the average number of employees with families**

Revisit our centered lm:

```{r} 
at_mean = lm(empsatis ~ scale(famprog, scale = F) * 
               scale(perfam, scale = F), data = d)
summary(at_mean)
```

Because we've centered (at the mean), the simple effects reported here are at the mean

So for the number of family programs at the mean of the percentage of families who use the programs, `b = .065, p = .07`

So, what did we mean above by the main effect? Lesson: don't rely on these terms to make yourself understood. Be clear in describing your interpretation and exactly what it means. This is also helpful in coming up with a good mechanistic interpretation. 

**(e) Interpret the answer by examining the effect of family programs on employee satisfaction for companies at +1SD and -1SD of mean % who use programs**

Say we want to know about companies that have a lot of employees with families who use these programs (+1SD). We calculate this by subtracting 1SD from centered value.

```{r sd above}
at_plus1SD = lm(empsatis ~ scale(famprog, scale = F) * 
                  I(scale(perfam, scale = F)-sd(perfam)), data = d)
summary(at_plus1SD)
```

So for the number of family programs at +1SD above the mean of the percentage of families who use programs, the effect of family programs on employee satisfaction is `b = .14, p < .01.`

*Remember that we subtract one SD to describe the effect at one SD above the mean! You're subtracting these levels from your centered variable, so in the case of -1 SD, so +1 SD*

Now, for companies with few families who use these programs, we'll look at -1SD below the mean of the percentage of families who use these programs

```{r sd below}
at_minus1SD = lm(empsatis ~ scale(famprog, scale = F) * 
                   I(scale(perfam, scale = F)+sd(perfam)), data = d)
summary(at_minus1SD)
```

`b = -.01, ns`

Answer: List the simple effects at each level.

For companies where few families use the family programs, the number of programs does not affect employee satisfaction, `b = -.01, t(64) = -.23, p >.80.` However, for companies where a lot of families use the family programs, the number of family programs is associated with higher employee satisfaction, `b = .14, t(64) = 2.70, p = .007.`

We can also plot these results to visualize the interaction:

```{r}
ggplot(d, 
       aes(x=scale(famprog), 
           y=empsatis)) +  # Adding color for mentill
  geom_point(shape=1) +  
  theme_bw() + 
  # effect of famprog on empsatis @mean perfam
  geom_abline(aes(intercept=at_mean$coefficients[1], 
                  slope=at_mean$coefficients[2]), colour='black') +
  # effect of famprog on empsatis -1 SD perfam
  geom_abline(aes(intercept=at_minus1SD$coefficients[1], 
                  slope=at_minus1SD$coefficients[2]), colour='red') +
  # effect of famprog on empsatis +1 SD perfam
  geom_abline(aes(intercept=at_plus1SD$coefficients[1], 
                  slope=at_plus1SD$coefficients[2]), colour='green')
```

**(f) What do you conclude? Write out the story. Remember to use the appropriate numbers to make the story as useful as possible!**

```{r descriptives}
mean(d$perfam)
mean(d$perfam)+sd(d$perfam)
mean(d$perfam)-sd(d$perfam)
```

## Contrasts

Let's say that we wanted to transform the predictors into categorical variables, using one or more categorical variables with different means on a quantitative variable. (*What kind of test is this?*)

There are a few different decisions we as researchers could make at this point. Do we want to create a categorical variable with two groups (*High and Low number of programs*) or multiple groups (*Low, Middle, and High number of programs*)? How should we split up our other variables of interest? These are examples of the subjective decisions you make as researchers!

To make two equal groups, we'll split the variable using the `median` function.  Then, we change it into a categorical variable using the `findInterval` function.  

```{r median}
quantfp2 = median(d$famprog); print(quantfp2)
d$famprogcat = findInterval(d$famprog, quantfp2)
str(d)

table(d$famprogcat)

d$FPcat <- factor(d$famprogcat, labels=c('lowprog','highprog'))
table(d$FPcat)
```

Another quick way to do this would be to find the median and then use the `ifelse` function to create the new variable.

```{r}
median(d$famprog)
d$Fcat <- ifelse(d$famprog<6, c('highprog'), c('lowprog'))

table(d$Fcat)
str(d)
```

To make three groups, we'll use the `quantile` function to divide our variable `perfam`, the percentage of employees with families in the organization, into thirds (*note that we've specified our probabilities as .33 and .66 accordingly). Again we change it into a categorical variable using the `findInterval` function.  This will allow us to have a categorical variable with three equal groups. 

```{r quantile}
quantpf3 = quantile(d$perfam, probs = c(.34, .66)); print(quantpf3)   
d$perfamcat = findInterval(d$perfam, quantpf3)  		

table(d$perfamcat)
str(d)

d$PerCat <- factor(d$perfamcat, labels=c('low use','middle use', 'high use'))
table(d$PerCat)
```

Here's another way to create multiple categories in your data!  We can specify our values calculated above, `r quantpf3`

```{r categorical option 2}
d$PCat[d$perfam<51.7] <- 'Low Use'
d$PCat[d$perfam>51.7 & d$perfam<59] <- 'Middle Use'
d$PCat[d$perfam>=59] <- 'High Use'

table(d$PCat)
```

```{r second look}
str(d) # note variables that are chr not factor! problem for contrasts
contrasts(d$Fcat)=cbind(-1,1)
```

Let's plot our data! 

```{r plotting}
with(d, 
     {interaction.plot(FPcat, PerCat, empsatis,
      xlab = 'Number of Programs',
      ylab = 'Employee Satisfaction',
      trace.label = 'Percentage Use'
                       ) })
```

How can we make bar graphs?  (Since we're using two categorical predictors)

We'll also add error bars! We'll include formulas for the 95% confidence interval and the standard error that you could use.

```{r formulas}
sem <- function(x) {sd(x) / sqrt(length(x))}

ci95 <- function(x) {sem(x) * 1.96}
```

```{r plotting error bars}
ms <- aggregate(empsatis ~ FPcat + PerCat, data=d, mean)
# note for the errs, you could use the formula for ci95 or sem
ms$errs <- aggregate(empsatis ~ FPcat + PerCat, data=d, sem)$empsatis
print(ms)

ggplot(ms, aes(x=FPcat, y=empsatis, fill=PerCat)) + 
  geom_bar(position=position_dodge(), stat="identity", colour="black", size=.3) + # Use black outlines
  geom_errorbar(aes(ymin = ms$empsatis-ms$errs, ymax=ms$empsatis+ms$errs), width=.2, position=position_dodge(width=.9)) +
  xlab("Number of Programs") +
  ylab("Employee Satisfaction") +
  theme_bw()
```

Let's revisit our data, but just take a look at the companies that had a low number of programs, since that seemed to be where interesting things were happening!

```{r subsetting data}
l = subset(d, FPcat=='lowprog')
str(l)
```

What if we change our contrasts? What predictions might we make using the data?

```{r contrasts}
qplot(PerCat, empsatis, data = d, geom = "boxplot")
levels(l$PerCat)

# here' are the's the default coding:
contrasts(l$PerCat)

# now let's change it
contrasts(l$PerCat) = cbind(c(1,1,-2), c(1,-1,0)) #which groups are these contrasts comparing?
contrasts(l$PerCat)

with(l, summary(lm(empsatis ~ PerCat)))
```

We've talked in class about contrasts that are orthogonal. Why do we want to create orthogonal contrasts?

Let's create a formula to test whether contrasts are orthogonal (if we have three groups)!

```{r}
c_orth_3 <- function(x) {(x[1,1]*x[1,2])+(x[2,1]*x[2,2])+(x[3,1]*x[3,2])}
```

Let's create some orthogonal and non-orthogonal contrasts and see if our function works.

```{r}
c1 <- cbind(c(-2,1,1), c(0,1,-1)); c_orth_3(c1)
c2 <- cbind(c(-2,1,1), c(1,1,-2)); c_orth_3(c2)
c3 <- cbind(c(-2,1,1), c(1,1,-3)); c_orth_3(c3) #Remember contrasts must sum to 0!
```

Now let's see if we can create a function for other contrasts!

```{r}
c_orth_4 <- function(x) {
  a <- (x[1,1]*x[1,2])+(x[2,1]*x[2,2])+(x[3,1]*x[3,2])+(x[4,1]*x[4,2]);
  b <- (x[1,2]*x[1,3])+(x[2,2]*x[2,3])+(x[3,2]*x[3,3])+(x[4,2]*x[4,3]);
  c <- (x[1,1]*x[1,3])+(x[2,1]*x[2,3])+(x[3,1]*x[3,3])+(x[4,1]*x[4,3]);
  d <- cbind(a,b,c); rownames(d)=c('Contrasts'); print(d)
  e <- a+b+c; names(e)=c('Sum'); print(e) }
```


```{r}
c1 <- cbind(c(-3,1,1,1), c(0,0,1,-1), c(-1,1,1,-1)); c_orth_4(c1)
c2 <- cbind(c(1,1,-1,-1), c(1,-1,1,-1), c(-1,1,1,-1)); c_orth_4(c2)
```

Let's take a closer look at each of these contrasts to see what groups they would be comparing!

```{r}
print(c2)
```


## Question E - Mediation!

Let's clean up our screens and load in the next data set!
```{r}
rm(list=ls())

d = read.csv('http://www.stanford.edu/class/psych252/data/caffeine.csv')

str(d)
```

**Measures**

What mediational question might we ask with these data?

**IV**: *Coffee* - 20 subjects in each group either had 0 cups, 2 cups, or 4 cups

**DV**: *Performance* - on a stats quiz with 10 problems, 5-89 points

**Possible Mediator 1**: *Number of problems attempted* (hyperactivity)

**Possible Mediator 2**: *Accuracy* - how likely they were to get a problem right if they tried (better success)

What should we do first?

Let's visualize the data:
```{r}
# Histogram overlaid with kernel density curve
ggplot(d, aes(x=perf)) + 
  geom_histogram(aes(y=..density..),
                 binwidth=5,
                 colour="black", fill="white") +
  geom_density(alpha=.2, fill="#FF6666")  # Overlay with transparent density plot

table(d$coffee)
```

We should probably recode coffee cups into number of coffee cups!

```{r}
summary(d)
d$cups = 0*as.numeric(d$coffee==1) + 2*as.numeric(d$coffee==2) + 4*as.numeric(d$coffee==3) 
table(d$cups)
```

```{r}
ggplot(d, 
       aes(x=cups, 
           y=perf, size=numprob)) +  # Adding color for mentill
  geom_point(shape=1, position=position_jitter(width=.5)) +  
  geom_smooth(method=lm, se=TRUE) +
  theme_bw()
```

First question: Does the number of problems attempted (hyperactivity) mediate the effect of coffee on performance?
What is our x (IV)?
Our y (DV)? Our mediator?

We need to run three models. There is one model that we never run (the effect of the mediator on the DV, without the IV included):
```{r}
with(d, summary(lm(perf~numprob)))
```

The first model we need to look at is the direct path, does coffee predict performance?  If not, we can abandon this whole endeavor!
```{r model 1}
problm1<-lm(perf~cups,data=d)
summary(problm1) # yes, it predicts, c=3.74
c<-problm1$coefficients[2]; c # We'll save our coefficients for our Sobel test later!

problm1<-lm(perf~coffee,data=d) # Note that we get the same results whether we recode coffee or not, just different coefficients
summary(problm1)
```

Now let's check out Model 2, whether the IV affects the mediator, in other words, does coffee predict the number of problems attempted?

```{r model 2}
problm2<-lm(numprob~cups,data=d)
summary(problm2) # yes, a=0.52
a<-summary(problm2)$coefficients[2,1]; a
s_a<-summary(problm2)$coefficients[2,2]; s_a
```

Our final model, Model 3, is the effect of coffee on performance mediated by the effect of the number of problems.
```{r model 3}
problm3<-lm(perf~cups+numprob,data=d)
summary(problm3) 

c_prime<-summary(problm3)$coefficients[2,1]; c_prime
b<-summary(problm3)$coefficients[3,1]; b
s_b<-summary(problm3)$coefficients[3,2]; s_b

# note, we can also get c_prime by subtracting a * b from our original c:
c_prime
c - a*b
```

The direct effect of coffee (c) disappeared and the number of problems attempted (b) is significant. We could answer yes, there is mediation, but let's be more formal.

Let's perform  the conventional Sobel test, adding in the standard error of a and standard error of b.
```{r sobel}
s_ab <- sqrt(b^2*s_a^2+a^2*s_b^2+s_a^2*s_b^2)
s_ab # standard error of a*b

a*b
a*b/s_ab

p_s_ab<-pnorm(a*b/s_ab, lower.tail=F)
p_s_ab # p of ratio of a*b over its s.e.
```

Now let's repeat the procedure for the second mediation analysis. The question now is: does accuracy meadiate the effect of coffee on performance? 

We did Model 1 above and have significant c (the direct path)

Now let's move on to Model 2, does coffee predict accuracy?

```{r second med}
accurm2<-lm(accur~cups,data=d)
summary(accurm2)
```

No, coffee consumption does not predict accuracy, so according to Baron & Kenny we can stop and conclude there is no mediation. But lets procede, using a=-0.00014.

```{r}
a2<-summary(accurm2)$coefficients[2,1]
s_a2<-summary(accurm2)$coefficients[2,2]
```

Now model 3, is the effect of coffee on performance mediated by the effect of accuracy?

```{r}
accurm3<-lm(perf~cups+accur,data=d)
summary(accurm3) # now the effect of coffee remains as well as an effect of accur.

b2<-summary(accurm3)$coefficients[3,1]
s_b2<-summary(accurm3)$coefficients[3,2]
```

Perform conventional sobel test, adding standard error of a and b.

```{r}
s_ab2 <- sqrt(b2^2*s_a2^2+a2^2*s_b2^2+s_a2^2*s_b2^2)
s_ab2 # standard error of a*b
p_s_ab2<-pnorm(a2*b2/s_ab2,lower.tail=F)
p_s_ab2 # p of ratio of a2*b2 over its s.e.
```

Conclusion: Coffee and accuracy both contribute to performance and in this case there is no mediation there. However, the effect of coffee is mediated by the number of problems attempted. 

Bootstrapped Mediation
------------------------

Using a modified version of Benoit's script, let's re-run the analysis from before:
```{r}
mediation_bootstrap = function(x, med, y, iterations = 1000){
  
  # setup some parameters
  N = length(x)
  df = as.data.frame(cbind(x, med, y))
  boot_ab = vector(length=iterations) # set up empty vector for storage
  
  # now go through a loop where we'll randomly sample, and get a a*b value
  for (i in 1:iterations){
    ind_boot = sample(c(1:N), N, replace=TRUE) # random indices
    df_boot = df[ind_boot,]
      
    iter_a = lm(df_boot$med ~ df_boot$x)$coefficients[2] # coeff of x
    iter_b = lm(df_boot$y ~ df_boot$med + df_boot$x)$coefficients[2] # coeff of mediator
    
    boot_ab[i] = iter_a * iter_b
  }
  
  # create plot
  hist(boot_ab,main=paste("Bootstrapped a*b, with",iterations,"iterations"),col="red");
  abline(v=0, col='black', lty=2, lwd=2)
  abline(v=c(quantile(boot_ab,c(.025,.975))), col='blue', lty=3)
  
  # Print results
  print("Bootstrap results:",quote=F);
  print(c(ab=mean(boot_ab)));
  print(quantile(boot_ab,c(.025,.975)))
  
  return(boot_ab)
}
```

```{r}
boot_ab = mediation_bootstrap(x=d$cups, med=d$numprob, y=d$perf, iterations=10000)
mean(boot_ab)

# compared to our ab from before:
a*b
```
